{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/programming-datascience/d8b96346e347b0b6942e16a33e64039c#file-actor-critic-cartpole-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "# import gym\n",
    "from pettingzoo.classic import connect_four_v3\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "from collections import namedtuple, deque\n",
    "from time import sleep\n",
    "# import supersuit as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "# Importing PyTorch here\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavedAction = namedtuple('SavedAction', ['log_prob', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'player_0': Dict(action_mask:Box(7,), observation:Box(6, 7, 2)), 'player_1': Dict(action_mask:Box(7,), observation:Box(6, 7, 2))}\n",
      "{'player_0': Discrete(7), 'player_1': Discrete(7)}\n"
     ]
    }
   ],
   "source": [
    "env = connect_four_v3.env()\n",
    "# env = ss.resize_v0(env, x_size=84, y_size=84)\n",
    "print(env.observation_spaces)\n",
    "print(env.action_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can move either left or right to balance the pole\n",
    "# Lets implement the Actor critic network\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, name, obs_shape, act_shape, buffer_size, lr=1e-2):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.obs_shape = obs_shape\n",
    "        self.name = name\n",
    "        self.games_played = 0\n",
    "        self.wins = 0\n",
    "        self.history = deque(maxlen=1000000)\n",
    "        self.conv1 = nn.Conv2d(2, 8, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.conv2 = nn.Conv2d(8, 12, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(12)\n",
    "#         self.maxpool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.calc_input_size(), 64)\n",
    "        self.actor = nn.Linear(64, act_shape) \n",
    "        self.critic = nn.Linear(64, 1) # Critic is always 1\n",
    "        self.saved_actions = deque(maxlen=buffer_size)\n",
    "        self.rewards = deque(maxlen=buffer_size)\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.trust = 0.35 # trust to new values\n",
    "        \n",
    "    def calc_input_size(self):\n",
    "        m = self.conv1(torch.zeros((1,)+self.obs_shape))\n",
    "#         print(m.shape)\n",
    "        m = self.bn1(m)\n",
    "#         print(m.shape)\n",
    "        m = self.conv2(m)\n",
    "#         print(m.shape)\n",
    "#         m = self.maxpool1(m)\n",
    "#         print(m.shape)\n",
    "        return int(np.prod(m.size()))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x.view((1,)+self.obs_shape)))\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "#         x = self.maxpool1(x)\n",
    "        x = F.relu(self.fc1(x.reshape(x.size()[0], -1)))\n",
    "        action_prob = F.softmax(self.actor(x), dim=-1)\n",
    "        state_values = self.critic(x)\n",
    "        return action_prob, state_values\n",
    "    \n",
    "    def select_action(self, state, mask):\n",
    "        state = torch.from_numpy(state).float()\n",
    "        probs, state_value = self.forward(state)\n",
    "        mask = torch.from_numpy(mask)\n",
    "#         print(probs)\n",
    "        m = Categorical(probs * mask)\n",
    "        try:\n",
    "            action = m.sample()\n",
    "        except RuntimeError:\n",
    "            action = torch.argmax(mask)\n",
    "#         action = torch.argmax(probs * mask)\n",
    "        self.saved_actions.append(SavedAction(m.log_prob(action), state_value))\n",
    "        return action.item()\n",
    "        # In this function, we decide whehter we want the block to move left or right,based on what the model decided\n",
    "        \n",
    "    def finish_episode(self):\n",
    "        # We calculate the losses and perform backprop in this function\n",
    "        R = 0\n",
    "        saved_actions = [x for x in self.saved_actions]\n",
    "    #     log_prob = torch.tensor([x.log_prob for x in model.saved_actions])\n",
    "    #     value = \n",
    "        policy_losses = []\n",
    "        value_losses =[]\n",
    "        returns = []\n",
    "        rewards = [x for x in self.rewards]\n",
    "\n",
    "        for r in rewards[::-1]:\n",
    "            R = r + 0.99 * R # 0.99 is our gamma number\n",
    "            returns.insert(0, R)\n",
    "        returns = torch.tensor(returns)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "\n",
    "        for (log_prob, value), R in zip(saved_actions, returns):\n",
    "#             advantage = R - value.item()\n",
    "            advantage = (R - value.item()) * self.trust\n",
    "\n",
    "            policy_losses.append(-log_prob * advantage)\n",
    "#             value_losses.append(F.smooth_l1_loss(value, torch.tensor([[R]])))\n",
    "            value_losses.append(F.smooth_l1_loss(value, value + torch.tensor([[advantage]])))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss = torch.stack(policy_losses).sum() + torch.stack(value_losses).sum()\n",
    "        loss.float().backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    #     del model.rewards[:]\n",
    "    #     del model.saved_actions[:]\n",
    "        self.rewards.clear()\n",
    "        self.saved_actions.clear()\n",
    "    \n",
    "    def save(self, suff=''):\n",
    "        if len(suff) > 0:\n",
    "            suff = '_'+suff\n",
    "        torch.save(self.state_dict(), f\"Connect4_models/Connect4_{self.name}{suff}.pt\")\n",
    "        \n",
    "    def load(self, suff=''):\n",
    "        if len(suff) > 0:\n",
    "            suff = '_'+suff\n",
    "        self.load_state_dict(torch.load(f\"Connect4_models/Connect4_{self.name}{suff}.pt\"))\n",
    "        \n",
    "    def game_done(self, reward):\n",
    "        self.games_played += 1\n",
    "        self.wins += 1 if reward > 0 else 0\n",
    "        self.history.append(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(episodes_max, t_max=1000):\n",
    "#     print('target reward:', env.spec.reward_threshold)\n",
    "    running_reward = 0\n",
    "    for i_episode in range(episodes_max): # We need around this much episodes\n",
    "        env.reset()\n",
    "        ep_reward = 0\n",
    "        reward = [0,0]\n",
    "        done = [0,0]\n",
    "        for t in range(t_max):\n",
    "            state, reward[t%2], done[t%2], _ = env.last()\n",
    "            reward[t%2] = float(reward[t%2])\n",
    "            players[t%2].rewards.append(reward[t%2])\n",
    "            if done[t%2]:\n",
    "                if all(done):\n",
    "                    players[t%2].game_done(reward[t%2])\n",
    "                    players[(t+1)%2].game_done(reward[(t+1)%2])\n",
    "                    break\n",
    "                env.step(None)\n",
    "                continue\n",
    "            action = players[t%2].select_action(state['observation'], state['action_mask'])\n",
    "#             ep_reward += reward\n",
    "            env.step(action)\n",
    "            \n",
    "            \n",
    "        running_reward = 0.05 * ep_reward + (1-0.05) * running_reward\n",
    "        model_1.finish_episode()\n",
    "        model_2.finish_episode()\n",
    "\n",
    "        print(\"\\rEpisode {}\\tmodel_1 wins: {:.2f}\\tmodel_2 wins: {:.2f}\".format(\n",
    "                i_episode + 1, model_1.wins, model_2.wins\n",
    "            ), end=' '*10)\n",
    "        if (i_episode + 1) % 100 == 0: # We will print some things out\n",
    "            print(\"\\rEpisode {}\\tmodel_1 wins: {:.2f}\\tmodel_2 wins: {:.2f}\".format(\n",
    "                i_episode + 1, model_1.wins, model_2.wins\n",
    "            ), end=' '*10)\n",
    "            print()\n",
    "            model_1.save('last')\n",
    "            model_2.save('last')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = False\n",
    "buffer_size = 50000\n",
    "\n",
    "obs = env.observation_spaces['player_0'].spaces['observation'].shape\n",
    "mask = env.observation_spaces['player_0'].spaces['action_mask'].shape[0]\n",
    "# obs = obs[0] * obs[1] * obs[2] + mask\n",
    "\n",
    "model_1 = ActorCritic('model1', obs[::-1], env.action_spaces['player_0'].n, buffer_size, lr=5e-4)\n",
    "model_2 = ActorCritic('model2', obs[::-1], env.action_spaces['player_0'].n, buffer_size, lr=1e-4)\n",
    "players = [model_1, model_2]\n",
    "\n",
    "if saved_model:\n",
    "    model_1.load('last')\n",
    "    model_2.load('last')\n",
    "    print('saves loaded')\n",
    "\n",
    "eps = np.finfo(np.float32).eps.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I tried to lower lr and found that less lr learns better and wins another model, __But! it`s in the beggining__  \n",
    "after ~2000-3000 games model with bigger learning rate wins more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tmodel_1 wins: 4080.00\tmodel_2 wins: 3905.00          \n",
      "Episode 101\tmodel_1 wins: 4143.00\tmodel_2 wins: 3942.00                                                                     \n",
      "Episode 201\tmodel_1 wins: 4200.00\tmodel_2 wins: 3985.00                                                                                                    \n",
      "Episode 301\tmodel_1 wins: 4259.00\tmodel_2 wins: 4026.00                                                                                                                                  \n",
      "Episode 401\tmodel_1 wins: 4317.00\tmodel_2 wins: 4068.00                                                                                                                        \n",
      "Episode 501\tmodel_1 wins: 4376.00\tmodel_2 wins: 4109.00                                                                                          \n",
      "Episode 601\tmodel_1 wins: 4437.00\tmodel_2 wins: 4148.00                                                                                                              \n",
      "Episode 701\tmodel_1 wins: 4507.00\tmodel_2 wins: 4178.00                                                                                                                        \n",
      "Episode 801\tmodel_1 wins: 4583.00\tmodel_2 wins: 4202.00                                                                                                                                            \n",
      "Episode 901\tmodel_1 wins: 4639.00\tmodel_2 wins: 4246.00                                                                                                    \n",
      "Episode 1001\tmodel_1 wins: 4699.00\tmodel_2 wins: 4286.00                                       \n",
      "Episode 1101\tmodel_1 wins: 4762.00\tmodel_2 wins: 4323.00                                                  \n",
      "Episode 1201\tmodel_1 wins: 4835.00\tmodel_2 wins: 4350.00                                                                                                                        \n",
      "Episode 1301\tmodel_1 wins: 4905.00\tmodel_2 wins: 4380.00                                                                                                              \n",
      "Episode 1401\tmodel_1 wins: 4966.00\tmodel_2 wins: 4419.00                                                                                          \n",
      "Episode 1501\tmodel_1 wins: 5027.00\tmodel_2 wins: 4458.00                                                            \n",
      "Episode 1601\tmodel_1 wins: 5088.00\tmodel_2 wins: 4497.00                                                                                                    \n",
      "Episode 1701\tmodel_1 wins: 5143.00\tmodel_2 wins: 4542.00                                                                                                                                  \n",
      "Episode 1801\tmodel_1 wins: 5201.00\tmodel_2 wins: 4584.00                                                                                                                                            \n",
      "Episode 1901\tmodel_1 wins: 5266.00\tmodel_2 wins: 4619.00                                                                                                                                                      \n",
      "Episode 2001\tmodel_1 wins: 5321.00\tmodel_2 wins: 4664.00                                                            \n",
      "Episode 2101\tmodel_1 wins: 5394.00\tmodel_2 wins: 4691.00                                                                                                              \n",
      "Episode 2201\tmodel_1 wins: 5461.00\tmodel_2 wins: 4724.00                                                                                                                                  \n",
      "Episode 2301\tmodel_1 wins: 5507.00\tmodel_2 wins: 4778.00                                                                                                              \n",
      "Episode 2401\tmodel_1 wins: 5550.00\tmodel_2 wins: 4835.00                                                                                                    \n",
      "Episode 2501\tmodel_1 wins: 5600.00\tmodel_2 wins: 4885.00                                                                                                    \n",
      "Episode 2601\tmodel_1 wins: 5643.00\tmodel_2 wins: 4942.00                                                                                                    \n",
      "Episode 2701\tmodel_1 wins: 5702.00\tmodel_2 wins: 4983.00                                                                                                                                            \n",
      "Episode 2801\tmodel_1 wins: 5761.00\tmodel_2 wins: 5024.00                                                                                                                        \n",
      "Episode 2901\tmodel_1 wins: 5819.00\tmodel_2 wins: 5066.00                                                                                                                        \n",
      "Episode 3001\tmodel_1 wins: 5877.00\tmodel_2 wins: 5108.00                                                                                                                                  \n",
      "Episode 3101\tmodel_1 wins: 5933.00\tmodel_2 wins: 5152.00                                                                                                                                  \n",
      "Episode 3201\tmodel_1 wins: 5991.00\tmodel_2 wins: 5193.00                                                                                                                                  \n",
      "Episode 3301\tmodel_1 wins: 6051.00\tmodel_2 wins: 5233.00                                                                                                                                  \n",
      "Episode 3401\tmodel_1 wins: 6106.00\tmodel_2 wins: 5278.00                                                                                \n",
      "Episode 3501\tmodel_1 wins: 6148.00\tmodel_2 wins: 5336.00                                                                                                                                                      \n",
      "Episode 3601\tmodel_1 wins: 6193.00\tmodel_2 wins: 5391.00                                                                                \n",
      "Episode 3701\tmodel_1 wins: 6250.00\tmodel_2 wins: 5434.00                                                                                                                        \n",
      "Episode 3801\tmodel_1 wins: 6288.00\tmodel_2 wins: 5496.00                                                                                                                        \n",
      "Episode 3901\tmodel_1 wins: 6315.00\tmodel_2 wins: 5569.00                                                                                          \n",
      "Episode 4001\tmodel_1 wins: 6352.00\tmodel_2 wins: 5632.00                                                                                                                        \n",
      "Episode 4101\tmodel_1 wins: 6406.00\tmodel_2 wins: 5677.00                                                                                                                                  \n",
      "Episode 4201\tmodel_1 wins: 6453.00\tmodel_2 wins: 5730.00                                                                                \n",
      "Episode 4301\tmodel_1 wins: 6511.00\tmodel_2 wins: 5772.00                                                            \n",
      "Episode 4401\tmodel_1 wins: 6546.00\tmodel_2 wins: 5837.00                                                                                \n",
      "Episode 4501\tmodel_1 wins: 6573.00\tmodel_2 wins: 5909.00                                                                      \n",
      "Episode 4601\tmodel_1 wins: 6603.00\tmodel_2 wins: 5979.00                                                                                          \n",
      "Episode 4701\tmodel_1 wins: 6633.00\tmodel_2 wins: 6049.00                                                                                                              \n",
      "Episode 4801\tmodel_1 wins: 6687.00\tmodel_2 wins: 6095.00                                                            \n",
      "Episode 4901\tmodel_1 wins: 6739.00\tmodel_2 wins: 6143.00                                                                                          \n",
      "Episode 5000\tmodel_1 wins: 6789.00\tmodel_2 wins: 6192.00                                                                                                                        "
     ]
    }
   ],
   "source": [
    "t_max = 500\n",
    "episodes_max = 5000\n",
    "train(episodes_max, t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.,  0.,  1.]), array([1081,    6,  913], dtype=int64))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(model_1.history), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1.wins = 913; games_played = 2000\n",
      "model_2.wins = 1081; games_played = 2000\n"
     ]
    }
   ],
   "source": [
    "print(f'{model_1.wins = }; games_played = {model_1.games_played}')\n",
    "print(f'{model_2.wins = }; games_played = {model_2.games_played}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There. we finished\n",
    "### Lets see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "pl1_wins = 4\tpl2_wins = 1\n"
     ]
    }
   ],
   "source": [
    "pl1_wins = 0\n",
    "pl2_wins = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in range(5):\n",
    "        env.reset()\n",
    "        reward = [0,0]\n",
    "        done = [0,0]\n",
    "        for t in range(100):\n",
    "            state, reward[t%2], done[t%2], _ = env.last()\n",
    "            env.render()\n",
    "            if done[t%2]:\n",
    "                if all(done):\n",
    "                    locals()[f'pl{t%2+1}_wins'] += 1 if reward[t%2] > 0 else 0\n",
    "                    locals()[f'pl{(t+1)%2+1}_wins'] += 1 if reward[(t+1)%2] > 0 else 0\n",
    "                    break\n",
    "                env.step(None)\n",
    "                continue\n",
    "            action = players[t%2].select_action(state['observation'], state['action_mask'])\n",
    "            env.step(action)\n",
    "            sleep(0.1)\n",
    "    env.close()\n",
    "print(f'{pl1_wins = }\\t{pl2_wins = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "players[0].select_action(state['observation'].flatten(), state['action_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "!start ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "(m1_sign),(m1_count) = np.unique(np.array(model_1.history), return_counts=True)\n",
    "(m2_sign),(m2_count) = np.unique(np.array(model_1.history), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _w_only(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    return x\n",
    "    \n",
    "wins_only = np.vectorize(_w_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_wins = np.cumsum(wins_only(model_1.history))\n",
    "m2_wins = np.cumsum(wins_only(model_2.history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(m1_wins, label='lr=5e-4')\n",
    "plt.plot(m2_wins, label='lr=1e-4')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('results2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO   ] [Logger      ] Record log in C:\\Users\\otnie\\.kivy\\logs\\kivy_21-08-19_1.txt\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.angle\" 0.3.0\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.glew\" 0.3.0\n",
      "[INFO   ] [deps        ] Successfully imported \"kivy_deps.sdl2\" 0.3.1\n",
      "[INFO   ] [Kivy        ] v2.0.0\n",
      "[INFO   ] [Kivy        ] Installed at \"D:\\Programming\\anaconda3\\lib\\site-packages\\kivy\\__init__.py\"\n",
      "[INFO   ] [Python      ] v3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "[INFO   ] [Python      ] Interpreter at \"D:\\Programming\\anaconda3\\python.exe\"\n",
      "[INFO   ] [Factory     ] 186 symbols loaded\n",
      "[INFO   ] [Image       ] Providers: img_tex, img_dds, img_sdl2, img_pil (img_ffpyplayer ignored)\n",
      "[INFO   ] [Text        ] Provider: sdl2\n",
      "[INFO   ] [Window      ] Provider: sdl2\n",
      "[INFO   ] [GL          ] Using the \"OpenGL\" graphics system\n",
      "[INFO   ] [GL          ] GLEW initialization succeeded\n",
      "[INFO   ] [GL          ] Backend used <glew>\n",
      "[INFO   ] [GL          ] OpenGL version <b'4.6.0 - Build 27.20.100.8681'>\n",
      "[INFO   ] [GL          ] OpenGL vendor <b'Intel'>\n",
      "[INFO   ] [GL          ] OpenGL renderer <b'Intel(R) UHD Graphics 620'>\n",
      "[INFO   ] [GL          ] OpenGL parsed version: 4, 6\n",
      "[INFO   ] [GL          ] Shading version <b'4.60 - Build 27.20.100.8681'>\n",
      "[INFO   ] [GL          ] Texture max size <16384>\n",
      "[INFO   ] [GL          ] Texture max units <32>\n",
      "[INFO   ] [Window      ] auto add sdl2 input provider\n",
      "[INFO   ] [Window      ] virtual keyboard not allowed, single mode, not docked\n",
      "[INFO   ] [Base        ] Start application main loop\n",
      "[INFO   ] [GL          ] NPOT texture support is available\n",
      "[INFO   ] [Base        ] Leaving application in progress...\n",
      " <kivy.uix.button.Button object at 0x0000011B96077430>\n"
     ]
    }
   ],
   "source": [
    "!python 4anim.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
